---
title: " Trabajo Práctico 1: The Multiarmed Bandit "
format:
  html:
    self-contained: true
    toc: true
    toc-title: "Tabla de Contenidos"
    number-sections: true
    code-fold: true
    highlight-style: pygments
    html-math-method: katex
    code-copy: true
    code-tools: true
    grid: # TODO: ir modificando.. (con otro documento más corto)
      body-width: 2000px # cuerpo documento
      sidebar-width: 100px # margen lateral en blanco
      margin-width: 350px # tabla de contenido
execute:
  warning: false
---

# Introducción

El *multi-armed bandit* nos enfrenta a tres máquinas tragamonedas. El juego de las maquinitas consiste en hacer girar sus rodillos (analógicos o digitales) con el objetivo de obtener una combinación de símbolos ganadora y así acceder a un premio monetario.

Cada máquina tiene una probabilidad de éxito desconocida y potencialmente diferente, es decir, una probabilidad distinta de entregar un premio. El desafío consiste en decidir a cuál máquina dedicar nuestras tiradas con el objetivo de maximizar las ganancias totales. Aquí es donde entra el dilema: ¿conviene *"explotar"* la máquina que hasta ahora ha dado mejores resultados, o *"explorar"* otras máquinas que podrían tener una tasa de éxito mayor pero aún desconocida?

En la fase inicial, cuando se sabe poco sobre las máquinas, podría ser más prudente *"explorar"*, probando cada máquina varias veces para obtener una estimación aproximada de sus probabilidades de éxito. A medida que se acumulan datos sobre el rendimiento de cada máquina, la estrategia podría cambiar a *"explotar"* la máquina que ha demostrado ser la más rentable. Sin embargo, siempre existe la incertidumbre y la posibilidad de que una de las máquinas menos utilizadas tenga en realidad una tasa de éxito mayor. Este problema se complica aún más por el hecho de que cada elección de máquina proporciona información que podría alterar nuestra comprensión de cuál es la mejor opción. La solución óptima a este problema involucra un equilibrio cuidadoso entre explorar para ganar información y explotar esa información para maximizar las ganancias.

En este trabajo práctico consideraremos la situación simplificada e imaginaria en la que no cuesta dinero jugar con una máquina. Es decir, si obtenemos una combinación ganadora, sumamos una unidad monetaria, pero si no, no perdemos nada. Supondremos, además, un escenario ficticio en que el deseo por descubrir cual es la máquina ganadora nos tendrá jugando los 366 días del año 2024. Lo que sí, cada día jugaremos con una sola máquina y volveremos al día siguiente...

# Objetivo

El objetivo del trabajo consiste en evaluar y comparar diferentes estrategias de juego. Se analizarán mediante simulaciones diferentes estrategias de exploración y explotación de la máquina. ¿Dónde aparece la inferencia bayesiana? Partiremos de una creencia *a priori* para la probabilidad de éxito de cada máquina y la iremos actualizando con cada jugada.

Para el estudio mediante simulaciones, consideraremos que las probabilidades de éxito de las tres máquinas son $\theta_a = 0.30$, $\theta_b = 0.55$ y $\theta_c = 0.45$. Recordemos que estas probabilidades son desconocidas (no podemos basar nuestras estrategias en esos valores, sino en las estimaciones que vamos haciendo de ellos).

# Desarrollo

### Recursos

```{r}
#| echo: true
#| label: requeriments
library(ggplot2)
library(dplyr)
library(cowplot)
library(gridExtra)
```

### Funciones

```{r}
#| echo: true
#| label: functions
graficar<-function(cont_tiradas, cont_exitos, wins, alphas, betas){
  df <- data.frame(maq = c("Maquina 1", "Maquina 2", "Maquina 3"),
                   freq = cont_tiradas,
                   exitos = cont_exitos,
                   fracasos = cont_tiradas - cont_exitos)
  g1<-ggplot(df, aes(x = maq, fill = maq)) +
    geom_bar(aes(y = freq ), stat = "identity", color = "black") +
    geom_bar(aes(y = exitos ), stat = "identity", color = "black") +
    geom_text(aes(y = exitos, label = "exitos"), position = position_stack(vjust = 0.5)) +
    geom_text(aes(y = freq, label = "fracasos"), position = position_stack(vjust = 0.8)) +
    labs(title = "Comparación de frecuencias",
         x = "Máquina",
         y = "Frecuencia") +
    theme_minimal() +
    guides(fill = guide_legend(title = "Máquinas"))
  
  
  # Crear el gráfico de ganancias
  df <- data.frame(dias = 1:366, wins=wins)
  g2<-ggplot(df, aes(x = dias, y = wins)) +
    geom_line(color = "blue")+
    labs(title = "Valores acumulados en 366 días",
         x = "Día",
         y = "Valor acumulado")
  
  # Crear el gráfico de postiriors
  x1=seq(0,1,length.out =200)
  posterior1=dbeta(x1,alphas[1],betas[1])
  posterior2=dbeta(x1,alphas[2],betas[2])
  posterior3=dbeta(x1,alphas[3],betas[3])
  
  df <- data.frame(
    theta = x1,
    posterior = rep(c(posterior1,posterior2, posterior3), time = 1),
    maquina = rep(c("Maquina 1", "Maquina 2", "Maquina 3"), each = length(x1))
  )
  
  g3<-ggplot(df)+
    aes(x = theta, y = posterior, color = maquina)+
    theme(legend.position = "right")+
    geom_line() +
    geom_area(aes(fill = maquina), alpha = 0.4, position = "identity") +
    labs(x = expression(theta), y = expression("p(" ~ theta ~ "| y)"))
  print(g1)
  print(g2)
  print(g3)
}
##############################################################################
al_azar <- function(lista1) {
  alphas <- lista1[[1]]
  betas <- lista1[[2]]
  tethas <- lista1[[3]]
  prior_df <- lista1[[4]]
  x1=seq(0,1,length.out =200)

  sample <- sample(1:length(alphas), 1)
  juego <- rbinom(1, 1, tethas[sample])
  alphas[sample] <- alphas[sample] + juego
  betas[sample] <- betas[sample] + 1 - juego
  
  postirior <- dbeta(x1, alphas[sample],  betas[sample])
  prior_df[, sample] <- postirior
  salida1_list <- list(alphas, betas, tethas, prior_df, sample, juego)
  return(salida1_list)
}
greedy_tasa_obs<-function(lista2){
  fl_calentamiento <- lista2[[5]]
  t <- lista2[[2]]
  tethas <- lista2[[1]]
  if (fl_calentamiento){
    sample <- sample(1:3, 1)
  }
  else{
    sample <- order(t + runif(3,0.001, 0.009), decreasing = TRUE)[1]
  }
  juego <- rbinom(1, 1, tethas[sample])
  lista2_salida<-list(tethas, t, juego, sample, fl_calentamineto)
  return(lista2_salida)
}
##############################################################################
greedy_prob_posterior<-function(lista3){
  tethas <- lista3[[1]]
  alphas <- lista3[[2]]
  betas <- lista3[[3]]
  
  esperanzas = c(alphas[1]/(alphas[1]+betas[1]),
                alphas[2]/(alphas[2]+betas[2]),
                alphas[3]/(alphas[3]+betas[3]))
  #print(esperanzas)
  sample <- order(esperanzas + runif(3,0.001, 0.009)  , decreasing = TRUE)[1]
  juego <- rbinom(1, 1, tethas[sample])
  alphas[sample] <- alphas[sample] + juego
  betas[sample] <- betas[sample] + 1 - juego
  
  lista3_salida<-list(tethas, alphas, betas, juego, sample)
  return(lista3_salida)
}
##############################################################################
e_greedy_tasa_obs<-function(lista4){
  e<-lista4[[3]]
  explote<-runif(1)
  lista4[[6]] = 0
  lista4[[7]] = 0
  if(explote<=1-e){#Elige el mejor
    lista4[[7]] = 1 # exploto
    sample <-  order(t + runif(3,0.001, 0.009), decreasing = TRUE)[1]
  }else{#Elige aleatoriamente 
    lista4[[6]] = 1 # exploro
    sample <-  as.numeric(sample(1:3, 1))
  }

  juego <- rbinom(1, 1, tethas[sample])
  lista4_salida<-list(tethas, t, e, juego, sample, lista4[[6]], lista4[[7]])
  return(lista4_salida)
}
##############################################################################

##############################################################################

##############################################################################
thompson_sampling <- function(lista7){
  alphas <- lista7[[1]]
  betas <- lista7[[2]]
  tethas <- lista7[[3]]
  muestra<- c(rbeta(1,alphas[1],betas[1]), 
               rbeta(1,alphas[2],betas[2]), 
               rbeta(1,alphas[3],betas[3]))
  #print(muestra)
  sample <- order(muestra, decreasing = TRUE)[1]
  juego <- rbinom(1, 1, tethas[sample])
  alphas[sample] <- alphas[sample] + juego
  betas[sample] <- betas[sample] + 1 - juego
  
  lista7_salida<-list(alphas, betas, tethas,  muestra, juego,  sample)
  return(lista7_salida)
}
```
